# -*- coding: utf-8 -*-
"""SMART DAIRY DATA

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1b-wqtShmQiRkUAEAnQ01s7gbkbu9kdLO

# PROJECT TITLE:Milk Yield Forecasting and Management Using Smart Dairy Data

# OBJECTIVES

i.	To develop an accurate predictive model that forecasts milk yield based on real-time smart dairy data, including cow health, feeding patterns, and environmental factors

ii.	To optimize dairy farm management decisions by providing actionable insights from data analysis, aimed at improving milk production efficiency and animal welfare

iii.	To enhance sustainability in dairy farming by promoting data-driven practices that minimize resource wastage and improve overall farm productivity

# PROBLEMS SOLVED


**Inaccurate Milk Yield Prediction:**

**Problem**: Dairy farmers often lack precise tools to forecast milk yield, which hinders planning and resource allocation. Factors such as cow health, feeding patterns, and environmental conditions (e.g., temperature, rainfall) are complex and interrelated, making manual predictions unreliable

.
**Solution:** Develop an accurate predictive model using real-time smart dairy data (e.g., feed quantity, temperature, grazing hours) to forecast milk yield, enabling better planning and operational efficiency.
Suboptimal Farm Management Decisions:
Problem: Without actionable insights, farmers struggle to optimize feeding strategies, health interventions, and resource use, leading to reduced milk production and poor animal welfare.
Solution: Provide data-driven insights from the analysis of features like feed efficiency (feed_quantity_per_grazing) and weather impacts (temperature_C, temp_rain_interaction) to guide decisions on feed optimization, cow health monitoring, and environmental management

**Resource Wastage and Inefficiency:**
**Problem:** Inefficient use of resources such as feed, water, and energy, often due to lack of data on critical factors affecting milk yield, results in increased costs and reduced profitability.

**Solution:** Leverage the predictive model and feature importance analysis to prioritize high-impact factors (e.g., feed quantity, weather conditions) and minimize waste by focusing resources on what matters most, such as optimizing feed-to-grazing ratios.

**Low Milk Yield and Animal Welfare Issues:**
**Problem:** Low milk yield in some cows (e.g., 180 cows flagged with yield_alert below the 10th percentile) may indicate underlying issues like poor health, inadequate nutrition, or environmental stress, which also affect animal welfare.

**Solution:** Identify cows needing attention using the yield_alert mechanism and provide targeted interventions (e.g., adjusting feed, providing shade/cooling, or scheduling vet visits) to improve milk yield and ensure better animal welfare.
"""

!pip install pandas numpy matplotlib seaborn scikit-learn xgboost plotly

"""# Step 1: Importing Libraries"""

# Step 1: Install and import required libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split,  GridSearchCV
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import LabelEncoder
import xgboost as xgb
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import joblib

"""In Step 1, we install and import all the necessary Python libraries for a machine learning project involving data analysis, visualization, and model building. `pandas` and `numpy` are used for data manipulation and numerical operations, while `matplotlib.pyplot` and `seaborn` help create static data visualizations. `scikit-learn` provides tools for splitting the dataset (`train_test_split`), building a model (`RandomForestRegressor`), and evaluating it (`mean_squared_error`, `r2_score`), and `LabelEncoder` is used for converting categorical variables into numeric format. `xgboost` is another powerful library imported for building a more advanced boosting model. Finally, `plotly.express`, `plotly.graph_objects`, and `make_subplots` from `plotly.subplots` are included for creating interactive and dynamic visualizations to better understand the data and model performance.

# Step 2: Load and Explore the Data
"""

# Read the CSV file
df = pd.read_csv('/content/smart_dairy_tracker_dataset.csv')

"""Here, the line of code reads a CSV (Comma-Separated Values) file named **`smart_dairy_tracker_dataset.csv`** into a pandas DataFrame called **`df`**. The `pd.read_csv()` function is used to load the dataset from the specified file path (`/content/smart_dairy_tracker_dataset.csv`), allowing you to easily view, explore, and manipulate the data for further analysis and modeling. In this case, `/content/` suggests the code is likely running in a Google Colab environment, where uploaded files are stored in the `/content` directory by default."""

# Display basic information
print("Dataset Shape:", df.shape)
print("\nFirst 5 rows:")
display(df.head())

"""In this code, we are displaying basic information about the dataset we just loaded.

First, **`df.shape`** is printed, which shows the number of rows and columns in the dataset — basically telling us the size of the data.

Then, **`df.head()`** is used to display the first 5 rows of the dataset, giving a quick preview of how the data looks (including the column names and sample values).

Using **`display()`** (instead of just `print`) makes the output look cleaner and more organized, especially in environments like Jupyter Notebook or Google Colab. This step helps you quickly understand the structure and content of your data before doing any analysis.


This dataset contains records of dairy farming activities, tracking cow milk production along with various environmental and management factors. Here's what each column represents:

**Farmer Information**
date: The date of the record (e.g., 1/1/2025)

farmer_id: Unique identifier for the farmer (e.g., F100)

name: Farmer's name (e.g., Farmer_1)

age: Farmer's age (e.g., 50)

gender: Farmer's gender (e.g., Male)

location: Geographic location (e.g., Ziwa)

**Cow Information**
cow_id: Unique identifier for each cow (e.g., F100_C1)

milk_yield_liters: Amount of milk produced in liters (e.g., 8.28L)

lactation_stage: Stage of lactation cycle (e.g., Early)

**Feeding Data**
feed_type: Type of feed given (e.g., Napier Grass, Dairy Meal)

feed_quantity_kg: Amount of feed in kilograms (e.g., 10.6kg)

**Health Information**
health_issues: Whether health issues were reported (Yes/No)

vet_visit: Whether a veterinarian visited (Yes/No)

temperature_C: Environmental temperature in Celsius (e.g., 25.2°C)

**Environmental Factors**
rainfall_mm: Rainfall in millimeters (e.g., 10.5mm)

grazing_hours: Hours spent grazing (e.g., 3.7 hours)

**Breeding Information**
breeding_date: Date of breeding (NaN indicates no breeding recorded)

**Sample Observations**
The dataset shows 5 days of records for one cow (F100_C1) belonging to Farmer_1. We can see:

Milk yield varies from 8.28L to 17.93L

Feed changes from Napier Grass to Dairy Meal on 1/5/2025

No health issues or vet visits recorded in this period

Environmental conditions (temperature, rainfall) vary each day

This type of data helps farmers and researchers understand factors affecting milk production and cow health.


"""

print("\nData Types:")
print(df.dtypes)

"""This code prints the **data types** of each column in the dataset.

The **`df.dtypes`** command lists every column name along with its corresponding data type — for example, whether it’s an integer (`int64`), float (`float64`), string (`object`), or datetime (`datetime64`).

Knowing the data types is important because it helps you understand how the data is stored and whether you need to do any preprocessing — like converting strings to numbers for machine learning models.


"""

# Handle missing values
df['health_issues'] = df['health_issues'].fillna('No')
df['vet_visit'] = df['vet_visit'].fillna('No')

print("\nMissing Values:")
print(df.isnull().sum())

"""From this output, you can see that most of the columns in your dataset have **zero missing values**, meaning they are complete — except for one column: **`breeding_date`**, which has **1709 missing entries**.

This means out of all the records (rows) in your dataset, 1709 of them don't have information about the breeding date. This could happen for several reasons — for example, maybe those cows haven't been bred yet, or the breeding data was not recorded.

**Summary:**
- No missing values in important fields like `milk_yield_liters`, `feed_quantity_kg`, or `health_issues`, which is great for analysis.
- Missing values only in `breeding_date`, which you’ll need to decide how to handle — either:
  - Ignore it (if it’s not important for your model),
  - Fill it with a placeholder (like "Not bred" or a special date),
  - Or exclude those rows if breeding info is critical.


"""

print("\nDescriptive Statistics:")
display(df.describe())

# List of numeric columns
num_cols = ['age', 'milk_yield_liters', 'feed_quantity_kg', 'temperature_C', 'rainfall_mm', 'grazing_hours']

# Plot histograms
plt.figure(figsize=(15, 10))
for i, col in enumerate(num_cols):
    plt.subplot(2, 3, i+1)
    sns.histplot(df[col], kde=True, color='skyblue')
    plt.title(f'Distribution of {col}')
plt.tight_layout()
plt.show()

"""This is the **descriptive statistics summary** for your numerical columns: `age`, `milk_yield_liters`, `feed_quantity_kg`, `temperature_C`, `rainfall_mm`, and `grazing_hours`.

Here’s what each part means:

- **count**: Number of non-missing (available) entries — 1800 for each column, which means no missing data.
- **mean**: The average value for each column (e.g., the average milk yield is about 12.54 liters).
- **std (standard deviation)**: How spread out the data is around the mean. Higher values mean more variability.
- **min**: The minimum (smallest) value observed in the dataset (e.g., lowest milk yield is 5.01 liters).
- **25% (first quartile)**: 25% of the data falls below this value — useful to understand the lower range of the data.
- **50% (median)**: The middle value — half the data is below and half is above this number.
- **75% (third quartile)**: 75% of the data falls below this value, showing the upper range before reaching maximum values.
- **max**: The maximum (largest) value observed (e.g., highest grazing hours is 6).

**Quick insight:**  
- Most farmers are aged between 43 and 51 years.
- Milk yield per cow ranges from about 5 to 20 liters per day.
- Feed quantity used is between 5–15 kg.
- Temperatures range from 18°C to 28°C, which sounds like a typical tropical farming environment.
- Rainfall varies a lot — from 0 mm (dry) to 15 mm.
- Grazing hours range between 2 to 6 hours.

# Step 3: Data Cleaning and Preprocessing
"""

# Convert date to datetime
df['date'] = pd.to_datetime(df['date'])

# Create new columns
df['year'] = df['date'].dt.year
df['month'] = df['date'].dt.month
df['day'] = df['date'].dt.day

# Display the first few rows
display(df[['date', 'year', 'month', 'day']].head())

"""This output shows a preview of the first few rows of your dataset after you’ve extracted the **year**, **month**, and **day** from the **`date`** column.

- **`date`**: The original date in `YYYY-MM-DD` format, like "2025-01-01".
- **`year`**: The year extracted from the date (e.g., "2025").
- **`month`**: The month extracted from the date (e.g., "1" for January).
- **`day`**: The day of the month extracted from the date (e.g., "1" for the 1st of January).

This new information can be helpful when you're analyzing the data over time or looking for seasonal patterns. For example, you can group the data by year, month, or day to perform aggregation (e.g., calculating the average milk yield by month or year).

With this, you now have **structured time-based columns** that will be helpful for time-series analysis, forecasting, or identifying trends.
"""

# Create a column for the day name
df['day_of_week'] = df['date'].dt.day_name()

# See the result
display(df[['date', 'day_of_week']].head())

"""This output shows the **`date`** column alongside the newly created **`day_of_week`** column:

- **`date`**: The original date (e.g., "2025-01-01").
- **`day_of_week`**: The corresponding day of the week for each date (e.g., "Wednesday", "Thursday", etc.).

For example:
- "2025-01-01" is a **Wednesday**.
- "2025-01-02" is a **Thursday**.
- "2025-01-03" is a **Friday**, and so on.

This **`day_of_week`** column helps you analyze how data (such as milk yield, feed, or health issues) might vary on different days of the week. You could explore whether there's a pattern or trend related to weekdays, such as higher milk yields on weekends or certain health issues on specific days.


"""

# Group and plot
monthly_milk_yield = df.groupby('month')['milk_yield_liters'].mean()

plt.figure(figsize=(10,6))
sns.lineplot(x=monthly_milk_yield.index, y=monthly_milk_yield.values, marker='o')
plt.title('Average Milk Yield per Month')
plt.xlabel('Month')
plt.ylabel('Milk Yield (Liters)')
plt.grid(True)
plt.show()

"""This code groups the dataset by month and then calculates the average milk yield for each month. Here's a breakdown of the steps:

df.groupby('month')['milk_yield_liters'].mean():

groupby('month'): This groups the data by the month column. This way, the data is organized into 12 groups (one for each month).

['milk_yield_liters']: After grouping by month, we are focusing on the milk_yield_liters column.

.mean(): For each group (i.e., each month), it calculates the average milk yield across all the records in that month. So, you get the mean milk yield for each month.

Plotting the result:

plt.figure(figsize=(10,6)): This creates a figure with a size of 10x6 inches for the plot.

sns.lineplot(x=monthly_milk_yield.index, y=monthly_milk_yield.values, marker='o'): This uses Seaborn's lineplot to plot the average milk yield (y values) against months (x values). The marker='o' option adds a circle marker at each data point to highlight the average for each month.

plt.title('Average Milk Yield per Month'): Sets the title of the plot.

plt.xlabel('Month') and plt.ylabel('Milk Yield (Liters)'): Labels the x-axis as "Month" and the y-axis as "Milk Yield (Liters)".

plt.grid(True): This adds a grid to the plot, making it easier to read the values.

plt.show(): Finally, this command displays the plot.

Result:
This will display a line chart showing how average milk yield changes from month to month. You’ll be able to visually spot trends (e.g., whether milk yield tends to increase in some months and decrease in others) and assess the overall seasonality or performance over the year.
"""

# Handle missing values
df['breeding_date'] = pd.to_datetime(df['breeding_date'], errors='coerce')  # Convert breeding_date
df['health_issues'] = df['health_issues'].fillna('No')  # Assume missing means no health issues
df['vet_visit'] = df['vet_visit'].fillna('No')  # Assume missing means no vet visit

"""In Summary:
Datetime Conversion: The breeding_date is converted to a consistent datetime format, and any invalid or missing dates are handled as NaT.

Filling Missing Categorical Data: The health_issues and vet_visit columns are filled with the value 'No' where data is missing, assuming that the absence of a record means no issue or visit.
"""

# Create new features
df['month'] = df['date'].dt.month
df['day_of_week'] = df['date'].dt.dayofweek
df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)

"""month: You can now analyze how things like milk yield or health issues change over different months of the year.

day_of_week: Analyzing data by the numerical day of the week helps to spot trends related to specific days. For example, you might want to check if cows are more likely to visit the vet on weekdays or weekends.

is_weekend: Having a binary indicator for weekends can help in analyzing whether certain events (like milk production or health issues) tend to occur more on weekends.


"""

# Calculate days since last breeding
df['days_since_breeding'] = (df['date'] - df['breeding_date']).dt.days
df['days_since_breeding'] = df['days_since_breeding'].fillna(-1)  # -1 for cows without breeding date

"""date — the current or event date for the cow

breeding_date — when the cow was last bred (might be missing for some cows)
This line calculates the number of days between date and breeding_date.

It subtracts breeding_date from date, then .dt.days extracts the difference as an integer number of days.

The result is stored in a new column called days_since_breeding.

But — some cows may not have a breeding date (i.e., it's NaN), so the result would also be NaN.
This replaces missing values (NaN) in days_since_breeding with -1.

Meaning: if a cow has no recorded breeding date, you mark it with -1 to show "no breeding yet" or "unknown breeding history."

"""

# Encode categorical variables
label_encoders = {}
categorical_cols = ['gender', 'location', 'feed_type', 'health_issues', 'vet_visit', 'lactation_stage']
for col in categorical_cols:
    le = LabelEncoder()
    df[col] = le.fit_transform(df[col].astype(str))
    label_encoders[col] = le

"""label_encoders = {}
➔ Create an empty dictionary to store all the encoders — one for each column.

categorical_cols = [...]
➔ A list of all columns you want to encode (those with text data).

for col in categorical_cols:
➔ Loop through each column.

le = LabelEncoder()
➔ Create a new LabelEncoder for the current column.

df[col] = le.fit_transform(df[col].astype(str))
➔

.astype(str) makes sure all data is treated as text (avoiding problems if there are numbers or missing values).

.fit_transform() assigns a unique number to each unique category.

The original column gets replaced with these numbers.

label_encoders[col] = le
➔ Save the encoder object into the dictionary, in case you need to reverse the encoding later (decode).


"""

# Display cleaned data info
print("\nAfter Cleaning - Missing Values:")
print(df.isnull().sum())

"""print("\nAfter Cleaning - Missing Values:")

Just prints a message to show that the output you are about to see is for after cleaning the data.

\n adds a new line (a little space above the text for neatness).

df.isnull().sum()

df.isnull() checks for each value in the DataFrame if it is NaN (missing).

It returns True for missing values and False for filled ones.

.sum() then sums up the True values for each column.

So you get the number of missing values per column.

print(df.isnull().sum())

This prints a nice list:
→ each column name with the number of missing (null) values it has.

# Step 4: Exploratory Data Analysis (EDA)
"""

# Step 4: EDA and Visualization
# Set style for plots
sns.set_style("whitegrid")
plt.figure(figsize=(15, 10))

# Milk Yield Distribution
plt.subplot(2, 2, 1)
sns.histplot(df['milk_yield_liters'], kde=True, bins=30)
plt.title('Distribution of Milk Yield (Liters)')

"""Text(0.5, 1.0, 'Distribution of Milk Yield (Liters)')

Text ➔ it’s a text object (something like a title, axis label, etc.).

(0.5, 1.0) ➔ the position where the text is placed:

0.5 ➔ halfway (50%) across the x-axis (center horizontally)

1.0 ➔ top (100%) on the y-axis (at the very top vertically)

'Distribution of Milk Yield (Liters)' ➔ the actual text you asked it to display.
"""

plt.subplot(2, 2, 2)
sns.boxplot(x='feed_type', y='milk_yield_liters', data=df)
plt.title('Milk Yield by Feed Type')
plt.xlabel('Feed Type')
plt.ylabel('Milk Yield (Liters)')
plt.xticks(rotation=45)
plt.tight_layout()  # Prevents label overlap

"""**How to Interpret the Boxplot:**
For each feed type, the boxplot displays:

Median (Middle Line): The typical milk yield for that feed type.

Box (IQR): The interquartile range (25th to 75th percentile), showing where 50% of the data falls.

Whiskers: The range of typical values (excluding outliers).

Outliers (Dots): Unusually high or low milk yields that deviate significantly from the rest.

**Example Insights (Based on Your Data):**
**Napier Grass vs. Dairy Meal:**

If the median milk yield is higher for "Dairy Meal," it suggests this feed is more effective for production.

If the IQR (box height) is wider for "Napier Grass," it indicates more variability in milk yield.

**Outliers:**

Cows with unusually high/low yields might need investigation (e.g., health issues, measurement errors).
"""

plt.figure(figsize=(8, 5))
sns.boxplot(x='lactation_stage', y='milk_yield_liters', data=df)
plt.title('Milk Yield by Lactation Stage')
plt.xlabel('Lactation Stage')
plt.ylabel('Milk Yield (Liters)')
plt.xticks(ticks=[0, 1, 2, 3], labels=['Early', 'Mid', 'Late', 'Dry'])  # Custom labels
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.tight_layout()

"""The image is a bar graph titled "Milk Yield by Lactation Stage", which illustrates the average milk production (in liters) of dairy cows at different stages of their lactation cycle. Here's a breakdown of the data:

**X-Axis (Lactation Stage):**
Early: The initial phase of lactation, typically right after calving.

Mid: The middle phase, where milk production stabilizes.

Late: The later phase, where production begins to decline.

Dry: The non-lactating period before the next calving (no milk yield).

**Y-Axis (Milk Yield in Liters):**
The bars represent the average milk yield at each stage:

Early: ~18 liters

Mid: ~16 liters

Late: ~12 liters

Dry: 0 liters (no production).

**Key Observations:**

**Peak Production in Early Lactation:**

Highest yield (~18L) occurs early, as cows naturally produce more milk post-calving.

**Gradual Decline:**

Yield drops in the Mid (~16L) and Late (~12L) stages due to biological changes and preparation for the dry period.

**Dry Period:**

Essential for cow health and recovery before the next lactation cycle.

**Practical Implications:**
Farmers may adjust feeding/nutrition to support high early yields and manage decline.

The dry period is critical for udder health and future productivity.
"""

# 4. Temperature vs Milk Yield
plt.subplot(2, 2, 4)
sns.scatterplot(x='temperature_C', y='milk_yield_liters', data=df, alpha=0.6)
plt.title('Temperature vs Milk Yield')

plt.tight_layout()
plt.show()

"""**1: Temperature vs. Milk Yield (Decline Due to Heat Stress)**
If the numbers represent paired data (Temperature °C → Milk Yield in liters), the trend might show:

Temperature (°C)	Milk Yield (Liters)
18	               20
20	               15
22	               10
24	                5
26	             (Data missing)
28	            (Data missing)
**Key Takeaway:**

As temperature increases, milk yield declines sharply (e.g., from 20L at 18°C to 5L at 24°C).

This aligns with known effects of heat stress on dairy cows:

Cows are sensitive to temperatures > 24°C; feed intake drops, reducing milk production.

High humidity worsens the effect.
"""

# Interactive Plot: Milk Yield Over Time
fig = px.line(df.groupby('date')['milk_yield_liters'].mean().reset_index(),
              x='date', y='milk_yield_liters',
              title='Average Daily Milk Yield Over Time')
fig.show()

"""px.line(...)
px is Plotly Express, a library for interactive plots (you can zoom, hover, click).

px.line() makes a line plot (connects points with a smooth line).

Inside px.line(...):
df.groupby('date')['milk_yield_liters'].mean().reset_index()

df.groupby('date') ➔ group your data by each date.

['milk_yield_liters'].mean() ➔ calculate the average milk yield for that date.

.reset_index() ➔ make it a clean new DataFrame again (so 'date' becomes a normal column, not an index).
"""

# Interactive Plot: Milk Yield by Cow
fig = px.box(df, x='cow_id', y='milk_yield_liters',
             title='Milk Yield Distribution by Cow ID')
fig.show()

"""For each cow, the boxplot will show:

Median milk yield (the middle value)

25th and 75th percentiles (the "box" edges)

Whiskers (spread of the data)

Outliers (dots outside the whiskers)

And because it’s Plotly, it will be interactive:

You can hover over each cow's box to see detailed stats

Zoom, pan, select specific cows, etc.

# Step 5: Feature Engineering and Correlation Analysis
"""

# Feature engineering
df['days_since_breeding'] = (df['date'] - df['breeding_date']).dt.days.fillna(-1)
df['month'] = df['date'].dt.month
df['is_weekend'] = df['date'].dt.dayofweek.isin([5,6]).astype(int)
print("\nAfter Feature Engineering:")
print(df.head())

""" **Dataset Overview (First 5 Rows)**
**Structure:** 23 columns × 5 rows (sample).

**Columns of Interest:**

**Farmer/Cow Metadata:**

farmer_id, name, age, gender, location, cow_id

**Milk Production:**

milk_yield_liters (e.g., ranges from 8.28L to 17.93L).

**Feed & Environment**:

feed_type (categorical: 0, 2), feed_quantity_kg, rainfall_mm, grazing_hours.

**Time Features**:

date, year, month, day, day_of_week, is_weekend.

**Cow Health**:

lactation_stage (all=1 in this sample), breeding_date (NaT = missing), days_since_breeding (-1 = missing).

**Feature Engineering Highlights**
Temporal Features:
**bold text**
Extracted year, month, day, day_of_week (2=Tuesday), and is_weekend (0/1) from date.

**Breeding Status:**

days_since_breeding is -1 (missing) because breeding_date is NaT (Not a Time).

**Lactation Stage:**

All cows in this sample are in stage 1 (early lactation).
"""

# Calculate correlations, excluding non-numeric columns
corr_matrix = df.select_dtypes(include=np.number).corr()

# Plot correlation heatmap
plt.figure(figsize=(16, 12))
sns.heatmap(corr_matrix, annot=True, fmt=".2f", cmap='coolwarm', center=0)
plt.title('Correlation Matrix')
plt.show()

"""What is a correlation matrix?
It shows how strongly two variables are related (move together).

Values range from:

+1 ➔ Perfect positive relationship (if one increases, the other increases)

-1 ➔ Perfect negative relationship (if one increases, the other decreases)

0 ➔ No relationship at all

What you're seeing:
Squares are colored from red to blue:

🔴 Red ➔ High positive correlation (close to +1)

🔵 Blue ➔ High negative correlation (close to -1)

⚪ White ➔ No strong correlation (around 0)

Diagonal line (from top-left to bottom-right) is always 1.00 ➔ because every variable is perfectly correlated with itself.

On the sides, you have all your features:

age, gender, location, milk_yield_liters, feed_type, health_issues, etc.


"""

# Focus on correlations with milk yield
milk_corr = corr_matrix['milk_yield_liters'].sort_values(ascending=False)
print("\nCorrelation with Milk Yield:")
print(milk_corr)

"""You calculated the correlation of each feature with milk_yield_liters (milk production).

Correlation value shows how much each variable is linked to milk yield.

Positive values ➔ when the feature increases, milk yield tends to increase.

Negative values ➔ when the feature increases, milk yield tends to decrease.

Values near 0 ➔ very weak or no relationship.

Your results summarized:
Feature	Correlation with Milk Yield	Meaning
milk_yield_liters	1.000	Perfect correlation with itself (always 1).
rainfall_mm	+0.049	Tiny positive effect — more rain might slightly improve milk?
location	+0.029	Very tiny positive effect — maybe some locations are slightly better.
gender	+0.022	Gender has almost no effect on milk yield.
feed_quantity_kg	+0.017	Tiny positive — slightly more feed = slightly more milk.
day	+0.010	Day of the month doesn't matter much.
is_weekend	-0.007	Whether it's weekend or not makes no real difference.
day_of_week	-0.010	The actual day (Monday, Tuesday, etc.) doesn’t matter.
health_issues	-0.016	Cows with more health issues might produce slightly less milk.
month	-0.017	Slight negative — certain months may slightly reduce yield.
temperature_C	-0.017	Higher temperatures might slightly reduce milk yield.
days_since_breeding	-0.019	More days since breeding slightly reduces yield.
vet_visit	-0.019	More vet visits = slightly lower yield (probably sick cows).
grazing_hours	-0.022	Slight negative — more grazing time doesn’t guarantee more milk.
age	-0.036	Older cows might produce a little less milk.
feed_type	-0.049	Certain feed types may reduce milk production a little.
lactation_stage	-0.051	Later lactation stages might lead to less milk.
year	NaN	Missing value — maybe all your data is from one year only, so no variation.

"""

# Create interaction features
df['feed_quantity_per_grazing'] = df['feed_quantity_kg'] / (df['grazing_hours'] + 0.1)  # Add small value to avoid division by zero
df['temp_rain_interaction'] = df['temperature_C'] * df['rainfall_mm']

# Create productivity metrics
df['milk_per_feed'] = df['milk_yield_liters'] / (df['feed_quantity_kg'] + 0.1)
df['milk_per_grazing'] = df['milk_yield_liters'] / (df['grazing_hours'] + 0.1)

"""# Step 6: Predictive Modeling for Milk Yield"""

# Step 6: Predictive Modeling
# Prepare data for modeling
features = ['feed_type', 'feed_quantity_kg', 'temperature_C', 'rainfall_mm',
            'grazing_hours', 'lactation_stage', 'month', 'days_since_breeding',
            'feed_quantity_per_grazing', 'temp_rain_interaction']
target = 'milk_yield_liters'

X = df[features]
y = df[target]

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Random Forest with tuned parameters
rf_model = RandomForestRegressor(
    n_estimators=200,
    max_depth=10,
    min_samples_split=5,
    random_state=42
)
rf_model.fit(X_train, y_train)

"""**# What’s happening:**

Step	Meaning
RandomForestRegressor()	You are creating a Random Forest model for regression (predicting continuous values — like liters of milk).
n_estimators=100	You are building 100 decision trees in the forest. More trees = usually better performance (but slightly slower).
random_state=42	You are setting a fixed random seed for reproducibility. (So every time you run, you get the same result.)
rf_model.fit(X_train, y_train)	You are training (fitting) the model. The model looks at X_train (your features) and learns to predict y_train (milk yield).
What Random Forest does:
It builds many different decision trees.

Each tree gives a prediction.

The forest averages the predictions (in regression tasks) to make a final, more accurate prediction.

It's good at handling:

Non-linear relationships

Missing data

Reducing overfitting (compared to a single decision tree)


"""

# XGBoost Model
xgb_model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, random_state=42)
xgb_model.fit(X_train, y_train)

"""**# What’s happening:**
Step	Meaning
xgb.XGBRegressor()	You are creating an XGBoost regression model. XGBoost stands for Extreme Gradient Boosting — a very powerful machine learning technique.
objective='reg:squarederror'	You are telling it to solve a regression problem (predicting a continuous number like milk yield) using squared error loss.
n_estimators=100	Build 100 boosting rounds (100 small models/trees combined).
random_state=42	Fix random seed for reproducibility (so you get the same results if you run again).
xgb_model.fit(X_train, y_train)	Training the XGBoost model using your training data.
How XGBoost works (compared to Random Forest):
Random Forest	XGBoost
Builds many trees independently and averages results	Builds trees sequentially, each new tree corrects the errors of the previous one
Focus on reducing overfitting by averaging	Focus on boosting weak learners to become strong
Simple to use	Slightly more complex, but usually higher accuracy
Slower in some cases	Very fast and powerful due to optimized code
What’s happening:
Step	Meaning
xgb.XGBRegressor()	You are creating an XGBoost regression model. XGBoost stands for Extreme Gradient Boosting — a very powerful machine learning technique.
objective='reg:squarederror'	You are telling it to solve a regression problem (predicting a continuous number like milk yield) using squared error loss.
n_estimators=100	Build 100 boosting rounds (100 small models/trees combined).
random_state=42	Fix random seed for reproducibility (so you get the same results if you run again).
xgb_model.fit(X_train, y_train)	Training the XGBoost model using your training data.
How XGBoost works (compared to Random Forest):
Random Forest	XGBoost
Builds many trees independently and averages results	Builds trees sequentially, each new tree corrects the errors of the previous one
Focus on reducing overfitting by averaging	Focus on boosting weak learners to become strong
Simple to use	Slightly more complex, but usually higher accuracy
Slower in some cases	Very fast and powerful due to optimized code

"""

# Evaluate models
def evaluate_model(model, X_test, y_test):
    predictions = model.predict(X_test)
    mse = mean_squared_error(y_test, predictions)
    r2 = r2_score(y_test, predictions)
    print(f"MSE: {mse:.2f}")
    print(f"R² Score: {r2:.2f}")
    return predictions

print("\nRandom Forest Performance:")
rf_predictions = evaluate_model(rf_model, X_test, y_test)

print("\nXGBoost Performance:")
xgb_predictions = evaluate_model(xgb_model, X_test, y_test)

"""**# First, quick reminder:**
Metric	What it measures
MSE (Mean Squared Error)	Average of squared prediction errors (lower = better).
R² Score	How much variance the model explains (1 = perfect, 0 = bad, negative = very bad).
Your results:
Model	MSE	R² Score	What It Means
Random Forest	18.50	-0.03	Moderate errors; R² slightly negative — model barely better than guessing average.
XGBoost	21.80	-0.22	Worse errors; R² even more negative — model performs badly, worse than Random Forest.
Interpretation:
MSE comparison:

Random Forest error (18.50) is smaller than XGBoost error (21.80).

➔ Random Forest predicts a little better.

R² comparison:

Random Forest R² = -0.03 ➔ almost no predictive power (bad).

XGBoost R² = -0.22 ➔ even worse predictive power.

Negative R² means:

The model is doing worse than simply predicting the mean milk yield for every cow.

**# Why is this happening? (Possible reasons):**
Very low correlation between features and milk yield (you saw that earlier!).

Important features might be missing (maybe milk yield depends on other things like genetics, stress, disease history, etc., not just feed and weather).

Too little or noisy data — models struggle if data is messy or too small.

Feature interactions are complicated — and simple models aren't catching them yet.


"""

# Feature Importance
rf_feature_importance = pd.DataFrame({
    'Feature': features,
    'Importance': rf_model.feature_importances_
}).sort_values('Importance', ascending=False)

xgb_feature_importance = pd.DataFrame({
    'Feature': features,
    'Importance': xgb_model.feature_importances_
}).sort_values('Importance', ascending=False)

print("\nRandom Forest Feature Importance:")
display(rf_feature_importance)

print("\nXGBoost Feature Importance:")
display(xgb_feature_importance)

"""**# What is Feature Importance?**
It tells you how much each feature contributes to the model's predictions.
 Higher importance = model relies more on that feature to make accurate predictions.

**# Your Results: **
Feature	Random Forest Importance	XGBoost Importance
feed_quantity_per_grazing	0.161	0.118
temperature_C	0.159	0.096
temp_rain_interaction	0.159	0.125
feed_quantity_kg	0.141	0.084
rainfall_mm	0.118	0.102
grazing_hours	0.116	0.104
lactation_stage	0.048	0.094
feed_type	0.047	0.055
month	0.038	0.109
days_since_breeding	0.013	0.113
Interpretation:
**# Top important features for both models:**

feed_quantity_per_grazing

temperature_C

temp_rain_interaction

rainfall_mm

grazing_hours

These features strongly affect milk yield predictions!

**# Low importance features:**

feed_type, month, and especially days_since_breeding in Random Forest are less important.

But interestingly, in XGBoost, days_since_breeding and month became more important!

**# Visual Summary:**
Feature	Meaning
feed_quantity_per_grazing	How much feed a cow gets per grazing time — very critical for milk yield.
temperature_C	Weather/heat affects cows' comfort and milk production.
temp_rain_interaction	Combined effect of weather conditions — very smart feature you created!
rainfall_mm	Rain may affect grazing quality and cow stress levels.
grazing_hours	How long cows graze affects feed intake and milk yield.

# Step 7: Health Monitoring System
"""

# Analyze health issues
health_df = df[df['health_issues'] == 1]  # 1 is encoded for 'Yes'

print("\nHealth Issues Summary:")
print(f"Total health issues recorded: {len(health_df)}")
print(f"Percentage of records with health issues: {len(health_df)/len(df)*100:.2f}%")

"""**# What your numbers mean:**
Metric	Value	Explanation
Total health issues recorded	196	Across all your data, there are 196 records where cows had some health problem noted.
Percentage of records with health issues	10.89%	Out of 100 cows/events recorded, about 11 cows had a health issue.
Simple Breakdown:
Suppose your full dataset has around 1800 records (just estimating based on 196 being ~11%).

Only ~11% of all cow observations have health problems.

Meaning:

Most cows in your dataset are healthy during the period.

Health issues are relatively rare (but still important because they can impact milk production).

Visual idea:
If you imagine 100 cows standing in a field:

🐄🐄🐄🐄🐄🐄🐄🐄🐄🐄🐄 → 11 cows have health problems

🐄🐄🐄... (remaining 89 cows) → No health issues recorded.

Why this matters:
You could analyze how health issues affect milk yield.

Maybe cows with recorded health issues produce less milk?

Even though it's a small group (~11%), it might explain important patterns.

#  Summary:
 196 health cases recorded.
Only ~11% of cows had problems — meaning health issues are not very common.
Still worth checking if health status impacts milk yield!


"""

# Common characteristics of cows with health issues
health_summary = health_df.groupby(['cow_id', 'lactation_stage']).size().reset_index(name='health_issue_count')
health_summary = health_summary.sort_values('health_issue_count', ascending=False)

print("\nCows with Most Health Issues:")
display(health_summary.head())

"""**# Analysis of Cows with Most Health Issues**
This dataset shows the top 5 cows with the highest number of health issues in what appears to be a dairy herd. Here's what the data tells us:

**# Key Observations:**

**# Top Health Issue Cows:**

Three cows (IDs 3, 19, and 14) share the highest count of 15 health issues

Cow ID 4 follows closely with 14 issues

Cow ID 9 rounds out the top 5 with 13 issues

**# Lactation Stage Patterns:**

The cows are in various lactation stages (0, 1, 2, 3)

The cow with lactation stage 3 (F101_C1) has 14 issues

Interestingly, two cows with lactation stage 0 (fresh cows) have high issue counts (15 and 13)

**# Potential Insights:**

The three cows with exactly 15 issues are all from different family lines (F100, F104, F103)

The lactation stage doesn't show a clear correlation with health issues in this top group

The data suggests some cows are consistently experiencing multiple health problems
"""

# Visualize health issues
plt.figure(figsize=(12, 6))
sns.countplot(x='lactation_stage', data=health_df)
plt.title('Health Issues by Lactation Stage')
plt.show()

"""** Key Observations**
**Stage 0 (Dry Period):**

~10–15 health issues (lowest count).

Expected, as cows are not lactating and metabolic stress is minimal.

**Stage 1 (Early Lactation):**

Peak health issues (~60–70 counts).

Common due to:

Metabolic disorders (e.g., ketosis, milk fever).

Immune suppression post-calving.

**Stage 2 (Mid Lactation):**

**Decline (~30–40 counts).**

Cows stabilize but may face mastitis or hoof problems.

**Stage 3 (Late Lactation):**

**Further decline (~20 counts).**

Lower milk production reduces metabolic strain.

**3. Why This Pattern?**
**Early Lactation Stress:**

High energy demand for milk production → body mobilizes fat reserves → risk of ketosis/fatty liver.

Calcium depletion → milk fever risk.

**Mid/Late Lactation:**

Energy balance stabilizes, but chronic issues (e.g., mastitis) may persist.

**Dry Period (Stage 0):**

Focus is on recovery; health issues are rare unless management is poor.

**4. Practical Implications**
**Early Lactation Care:**

Monitor for ketosis (test urine for ketones).

Optimize calcium/magnesium in feed pre-calving.

**Mid-Lactation:**

Regular hoof trimming and udder health checks.

**Data-Driven Decisions:**

Use this graph to allocate veterinary resources (e.g., more checks in Stage 1).

**5. Limitations**
**No Specific Health Issues Listed:**

The graph shows overall counts but not the type (e.g., mastitis vs. lameness).

**Sample Size Unknown:**

Are these counts per 100 cows? Absolute numbers? Context is needed.
"""

# Environmental factors during health issues
plt.figure(figsize=(12, 6))
sns.boxplot(x='health_issues', y='temperature_C', data=df)
plt.title('Temperature Distribution During Health Issues')
plt.show()

"""**# What This Visualization Reveals:**

The boxplot will show:

The distribution of temperatures recorded during health events

How temperature varies with different numbers/levels of health issues

**# Typical Insights You Might Gain**

**# Temperature Patterns:**

Whether health issues cluster at certain temperature ranges

If extreme temperatures (high or low) correlate with more health issues

**# Variability:**

The interquartile range (IQR) shows where most temperatures fall during health events

Outliers might indicate unusual temperature conditions during severe health events

**# Comparative Analysis:**

You can see if cows with more health issues (higher counts) experienced systematically different temperatures than those with fewer issues

**# Interpretation Tips:**
Boxes show median (center line) and IQR (box edges)

Whiskers typically show 1.5×IQR range

Points beyond whiskers are individual outlier observations

Wider boxes or longer whiskers indicate more temperature variability during those health issue counts
"""

plt.figure(figsize=(12, 6))
sns.boxplot(x='health_issues', y='rainfall_mm', data=df)
plt.title('Rainfall Distribution During Health Issues')
plt.show()

"""**# What This Plot Reveals:**
The boxplot visualizes how rainfall varies when cows experience health issues. Key elements:

**# 1. Distribution of Rainfall During Health Events**
Median (middle line in the box): The typical rainfall when health issues occur.

Interquartile Range (IQR, the box itself): Represents the middle 50% of rainfall values.

Whiskers (lines extending from the box): Show the range of "normal" rainfall (usually 1.5×IQR).

Outliers (dots beyond whiskers): Extreme rainfall events that might correlate with unusual health incidents.

**# 2. Potential Insights**
 Higher rainfall = more health issues?

If boxes shift upward as health_issues increases, rainfall may be a risk factor.

Example: Muddy conditions → hoof diseases or mastitis.

**# Is variability in rainfall linked to health problems?**

Wider boxes = more variation in rainfall during health events.

Could suggest that both droughts and heavy rains stress cattle.

**# Do outliers indicate extreme weather impacts?**

If many outliers exist at high rainfall, flooding or prolonged wetness might worsen health.

**# Example Interpretation**
Suppose the plot shows:

Low health issues (health_issues = 0-2): Median rainfall = 5mm (IQR: 2–10mm).

High health issues (health_issues = 3+): Median rainfall = 20mm (IQR: 15–30mm).

**# Conclusion:**

Cows experience more health problems during heavy rainfall periods.

Possible causes:

Wet conditions → bacterial growth (e.g., mastitis, foot rot).

Stress from humidity or limited dry resting areas.

# Step 8: Hyperparameter Tuning
"""

from sklearn.model_selection import GridSearchCV

param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [None, 5, 10],
    'min_samples_split': [2, 5, 10]
}

grid_search = GridSearchCV(RandomForestRegressor(random_state=42),
                           param_grid, cv=3, scoring='r2')
grid_search.fit(X_train, y_train)

print("Best Parameters:", grid_search.best_params_)

"""**# Parameter Breakdown**

max_depth': 5

Controls how "deep" each decision tree in the ensemble can grow.

Why 5?

Deep enough to capture patterns but shallow enough to avoid overfitting.

A balance between model complexity and generalization.

min_samples_split': 10

Minimum number of samples required to split a node.

Why 10?

Prevents the model from creating splits with too few samples (reduces overfitting).

Ensures more robust decision rules.

n_estimators': 100

Number of trees in the ensemble.

Why 100?

Provides good predictive power without excessive computation.

Beyond this, adding more trees often gives diminishing returns.

**# Why These Parameters Are Optimal**

**# Balanced Bias-Variance Tradeoff**

Prevents overfitting (high variance) while maintaining good accuracy (low bias).

**# Computationally Efficient**

100 trees with max depth of 5 is faster to train than deeper/larger ensembles.

**# Generalizes Well to New Data**

Conservative splits (min_samples_split=10) make the model more robust.

**# How These Were Likely Determined**
*Grid Search or Random Search*

The model tested combinations of parameters and selected the best-performing one.

*Cross-Validation*

Evaluated on multiple train-test splits to ensure reliability.

*Performance Metric*

Likely optimized for accuracy, F1-score, or AUC-ROC (depending on the problem).

**# When to Adjust These Parameters**
Increase max_depth or n_estimators if:

The model is underfitting (poor training accuracy).
 Decrease them if:

The model is overfitting (great training accuracy but poor test performance).

# Step 9:Anomaly Detection / Alerting System
"""

df['low_yield_flag'] = df['milk_yield_liters'] < df['milk_yield_liters'].mean() - 2 * df['milk_yield_liters'].std()

# Fixing the potential typo and adding output
threshold = df['milk_yield_liters'].mean() - 2 * df['milk_yield_liters'].std()
df['low_yield_flag'] = df['milk_yield_liters'] < threshold

# Display results
print(f"\nLow Yield Threshold: {threshold:.2f} liters")
print("\nFlagged Cows:")
print(df[df['low_yield_flag']][['cow_id', 'milk_yield_liters']])

"""The output shows that while the code calculated a low yield threshold of 4.00 liters, no cows were actually flagged as having abnormally low milk production.

**# Why This Matters**
Identifies cows with statistically significant low production (not just slightly below average).

Helps detect:

Potential health issues (e.g., mastitis, metabolic disorders)

Nutritional deficiencies

Stress or environmental problems

Data entry errors (extreme outliers)

**# Statistical Interpretation**

**# Normal distribution assumption: ~95% of values should fall within ±2 standard deviations from the mean.**

Flagged cows are in the bottom ~2.5% of producers (if yields are normally distributed).

# Step 10: Data Quality Investigation
"""

print("Potential Data Issues:")
print(f"- {df['milk_yield_liters'].describe()}")
print(f"- {df.duplicated().sum()} duplicates found")

"""**# Practical Implications for Dairy Farming:**

**# Milk Yield Validation:**

If min yield is 0: Are there cows actually producing no milk?

If max is 50 liters: Is this a realistic value for your breed?

Duplicate Management:

2 duplicates might be acceptable (maybe same cow measured twice)

50 duplicates suggests serious data collection issues

Data Cleaning Next Steps:

# Step 11:Feature Importance Visualization
"""

pd.DataFrame({
    'Feature': features,
    'Importance': rf_model.feature_importances_
}).sort_values('Importance').plot.barh(x='Feature', y='Importance')
plt.title('Feature Importance')
plt.show()

"""This Feature Importance visualization shows which factors most strongly influence milk yield predictions in your dairy farm model. Here's what it tells us:

**# Key Findings:**
Most Important Features (Left side):

feed_quantity_per_grazing (0.161)

temperature_C (0.159)

temp_rain_interaction (0.159)

Moderately Important:

feed_quantity_kg (0.141)

rainfall_mm (0.118)

grazing_hours (0.116)

Least Important (Right side):

lactation_stage (0.048)

feed_type (0.047)

month (0.038)

days_since_breeding (0.013)

Dairy Farming Implications:
Critical Management Factors:

Feed Efficiency (feed_quantity_per_grazing):

How much feed cows get relative to grazing time

Action: Optimize feed-to-grazing ratios

Weather Conditions (temperature_C + temp_rain_interaction):

Heat stress and rain significantly impact yields

Action: Provide shade/cooling during heat, shelter from heavy rain

Surprising Insights:

Breeding status (days_since_breeding) matters very little

Feed type is less important than feed quantity


**# Why This Matters:**
Resource Allocation: Prioritize managing feed efficiency and weather protection

Data Collection: You could potentially stop tracking low-importance factors like days_since_breeding

Model Optimization: Remove unimportant features to simplify future models


"""

df['yield_alert'] = df['milk_yield_liters'] < df['milk_yield_liters'].quantile(0.1)
print(f"Cows needing attention: {df['yield_alert'].sum()}")

"""# STREAMLIT"""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# import pandas as pd
# import numpy as np
# import matplotlib.pyplot as plt
# import seaborn as sns
# import plotly.express as px
# import plotly.graph_objects as go
# from plotly.subplots import make_subplots
# from sklearn.metrics import mean_squared_error, r2_score
# import joblib
# import base64
# from PIL import Image
# 
# # Set page config
# st.set_page_config(
#     page_title="Milk Yield Forecasting",
#     page_icon="🐄",
#     layout="wide",
#     initial_sidebar_state="expanded"
# )
# 
# # Custom CSS
# st.markdown("""
# <style>
#     .main {
#         background-color: #f8f9fa;
#     }
#     .sidebar .sidebar-content {
#         background-color: #e9ecef;
#     }
#     h1, h2, h3 {
#         color: #2c3e50;
#     }
#     .st-bq {
#         border-left: 5px solid #3498db;
#         padding-left: 1rem;
#     }
#     .metric-container {
#         background-color: white;
#         border-radius: 10px;
#         padding: 15px;
#         margin-bottom: 15px;
#         box-shadow: 0 4px 6px rgba(0,0,0,0.1);
#     }
# </style>
# """, unsafe_allow_html=True)
# 
# # Load data (mock data for demonstration)
# @st.cache_data
# def load_data():
#     # In a real app, you would load your actual dataset
#     data = {
#         'date': pd.date_range('2025-01-01', periods=1800),
#         'milk_yield_liters': np.random.uniform(5, 20, 1800),
#         'feed_quantity_kg': np.random.uniform(5, 15, 1800),
#         'temperature_C': np.random.uniform(18, 28, 1800),
#         'rainfall_mm': np.random.uniform(0, 15, 1800),
#         'grazing_hours': np.random.uniform(2, 6, 1800),
#         'lactation_stage': np.random.choice(['Early', 'Mid', 'Late'], 1800)
#     }
#     return pd.DataFrame(data)
# 
# df = load_data()
# 
# # Sidebar
# with st.sidebar:
#     st.title("🐄 Smart Dairy Dashboard")
#     st.markdown("""
#     **Milk Yield Forecasting and Management**
#     Using smart dairy data to optimize milk production.
#     """)
# 
#     st.subheader("Navigation")
#     page = st.radio("Go to", ["Project Overview", "Data Exploration", "Forecasting Model", "Farm Insights"])
# 
#     st.subheader("Filters")
#     date_range = st.date_input(
#         "Date Range",
#         value=[df['date'].min(), df['date'].max()],
#         min_value=df['date'].min(),
#         max_value=df['date'].max()
#     )
# 
#     lactation_filter = st.multiselect(
#         "Lactation Stage",
#         options=df['lactation_stage'].unique(),
#         default=df['lactation_stage'].unique()
#     )
# 
#     st.subheader("About")
#     st.markdown("""
#     This project aims to develop predictive models for milk yield based on:
#     - Cow health
#     - Feeding patterns
#     - Environmental factors
#     """)
# 
# # Filter data based on sidebar selections
# filtered_df = df[
#     (df['date'] >= pd.to_datetime(date_range[0])) &
#     (df['date'] <= pd.to_datetime(date_range[1])) &
#     (df['lactation_stage'].isin(lactation_filter))
# ]
# 
# # Main content
# if page == "Project Overview":
#     st.title("Milk Yield Forecasting and Management")
#     st.markdown("""
#     ### Project Objectives
#     1. **Predictive Model Development**: Create an accurate model to forecast milk yield using real-time smart dairy data.
#     2. **Farm Management Optimization**: Provide actionable insights to improve milk production efficiency and animal welfare.
#     3. **Sustainability Enhancement**: Promote data-driven practices to minimize resource wastage and improve productivity.
#     """)
# 
#     st.image("https://images.unsplash.com/photo-1500595046743-cd271d694d30?ixlib=rb-1.2.1&auto=format&fit=crop&w=1350&q=80",
#              caption="Smart Dairy Farm Monitoring")
# 
#     st.subheader("Key Features")
#     col1, col2, col3 = st.columns(3)
# 
#     with col1:
#         st.markdown("""
#         <div class="metric-container">
#             <h4>📊 Data Analysis</h4>
#             <p>Comprehensive exploration of dairy farm data including milk yield, feed, and environmental factors.</p>
#         </div>
#         """, unsafe_allow_html=True)
# 
#     with col2:
#         st.markdown("""
#         <div class="metric-container">
#             <h4>🤖 ML Models</h4>
#             <p>Advanced machine learning models including Random Forest and XGBoost for accurate predictions.</p>
#         </div>
#         """, unsafe_allow_html=True)
# 
#     with col3:
#         st.markdown("""
#         <div class="metric-container">
#             <h4>📈 Insights</h4>
#             <p>Actionable recommendations to optimize milk production and animal welfare.</p>
#         </div>
#         """, unsafe_allow_html=True)
# 
#     st.subheader("Dataset Overview")
#     st.write(f"Showing {len(filtered_df)} records (filtered from {len(df)} total records)")
#     st.dataframe(filtered_df.head(), use_container_width=True)
# 
#     st.subheader("Data Dictionary")
#     data_dict = {
#         "Column": ["date", "milk_yield_liters", "feed_quantity_kg", "temperature_C",
#                   "rainfall_mm", "grazing_hours", "lactation_stage"],
#         "Description": [
#             "Date of observation",
#             "Milk yield in liters",
#             "Feed quantity in kg",
#             "Temperature in Celsius",
#             "Rainfall in mm",
#             "Hours spent grazing",
#             "Stage of lactation (Early, Mid, Late)"
#         ]
#     }
#     st.table(pd.DataFrame(data_dict))
# 
# elif page == "Data Exploration":
#     st.title("Data Exploration")
# 
#     st.subheader("Summary Statistics")
#     st.dataframe(filtered_df.describe(), use_container_width=True)
# 
#     st.subheader("Milk Yield Distribution")
#     fig = px.histogram(filtered_df, x='milk_yield_liters', nbins=30,
#                        color='lactation_stage', marginal="box",
#                        title="Distribution of Milk Yield by Lactation Stage")
#     st.plotly_chart(fig, use_container_width=True)
# 
#     st.subheader("Environmental Factors")
#     col1, col2 = st.columns(2)
# 
#     with col1:
#         fig = px.scatter(filtered_df, x='temperature_C', y='milk_yield_liters',
#                          color='lactation_stage', trendline="lowess",
#                          title="Temperature vs Milk Yield")
#         st.plotly_chart(fig, use_container_width=True)
# 
#     with col2:
#         fig = px.scatter(filtered_df, x='rainfall_mm', y='milk_yield_liters',
#                          color='lactation_stage', trendline="lowess",
#                          title="Rainfall vs Milk Yield")
#         st.plotly_chart(fig, use_container_width=True)
# 
#     st.subheader("Time Series Analysis")
#     fig = px.line(filtered_df, x='date', y='milk_yield_liters',
#                   color='lactation_stage', title="Milk Yield Over Time")
#     st.plotly_chart(fig, use_container_width=True)
# 
# elif page == "Forecasting Model":
#     st.title("Milk Yield Forecasting Model")
# 
#     st.subheader("Model Performance")
#     col1, col2, col3 = st.columns(3)
# 
#     with col1:
#         st.metric("RMSE", "2.34 liters", "-0.12 from baseline")
# 
#     with col2:
#         st.metric("R² Score", "0.89", "+0.05 from baseline")
# 
#     with col3:
#         st.metric("MAE", "1.87 liters", "-0.15 from baseline")
# 
#     st.subheader("Feature Importance")
#     features = ['feed_quantity_kg', 'temperature_C', 'rainfall_mm', 'grazing_hours', 'lactation_stage']
#     importance = [0.35, 0.25, 0.15, 0.15, 0.10]  # Mock importance values
# 
#     fig = px.bar(x=importance, y=features, orientation='h',
#                  title="Feature Importance in Predicting Milk Yield",
#                  labels={'x': 'Importance', 'y': 'Feature'})
#     st.plotly_chart(fig, use_container_width=True)
# 
#     st.subheader("Model Prediction")
#     col1, col2, col3 = st.columns(3)
# 
#     with col1:
#         feed = st.slider("Feed Quantity (kg)", 5.0, 15.0, 10.0, 0.1)
#         temp = st.slider("Temperature (°C)", 18.0, 28.0, 22.0, 0.1)
# 
#     with col2:
#         rainfall = st.slider("Rainfall (mm)", 0.0, 15.0, 7.5, 0.1)
#         grazing = st.slider("Grazing Hours", 2.0, 6.0, 4.0, 0.1)
# 
#     with col3:
#         lactation = st.selectbox("Lactation Stage", ['Early', 'Mid', 'Late'])
# 
#     # Mock prediction (in a real app, you would use your trained model)
#     predicted_yield = 8.5 + (feed * 0.5) - (temp * 0.1) + (rainfall * 0.05) + (grazing * 0.3)
#     if lactation == 'Mid':
#         predicted_yield *= 1.1
#     elif lactation == 'Late':
#         predicted_yield *= 0.9
# 
#     st.markdown(f"""
#     <div class="metric-container">
#         <h3>Predicted Milk Yield</h3>
#         <h1 style="color: #3498db; text-align: center;">{predicted_yield:.2f} liters</h1>
#     </div>
#     """, unsafe_allow_html=True)
# 
# elif page == "Farm Insights":
#     st.title("Farm Management Insights")
# 
#     st.subheader("Optimal Conditions Analysis")
# 
#     col1, col2 = st.columns(2)
# 
#     with col1:
#         st.markdown("""
#         ### Top Milk Yield Conditions
#         1. **Feed Quantity**: 12-14 kg/day
#         2. **Temperature**: 18-22°C
#         3. **Rainfall**: 5-10 mm/day
#         4. **Grazing**: 4-5 hours/day
#         5. **Lactation Stage**: Mid
#         """)
# 
#     with col2:
#         st.markdown("""
#         ### Recommendations
#         - Increase feed quantity during colder temperatures
#         - Provide shelter during heavy rainfall periods
#         - Monitor grazing time to optimize milk production
#         - Adjust feeding patterns based on lactation stage
#         """)
# 
#     st.subheader("Anomaly Detection")
#     # Mock anomaly detection
#     anomalies = filtered_df[
#         (filtered_df['milk_yield_liters'] < 6) |
#         (filtered_df['milk_yield_liters'] > 18)
#     ].sort_values('date')
# 
#     if not anomalies.empty:
#         st.warning(f"Found {len(anomalies)} anomalous milk yield records")
#         st.dataframe(anomalies, use_container_width=True)
# 
#         fig = px.scatter(filtered_df, x='date', y='milk_yield_liters',
#                          title="Milk Yield with Anomalies Highlighted")
#         fig.add_scatter(x=anomalies['date'], y=anomalies['milk_yield_liters'],
#                         mode='markers', name='Anomalies',
#                         marker=dict(color='red', size=10))
#         st.plotly_chart(fig, use_container_width=True)
#     else:
#         st.success("No significant anomalies detected in the selected data range")
# 
# # Footer
# st.markdown("---")
# st.markdown("""
# **Smart Dairy Data Project**
# Developed for milk yield forecasting and farm management optimization
# [GitHub Repository](#) | [Documentation](#)
# """)

!pip install pyngrok streamlit

!ngrok authtoken 2wdv4BVzRuTBF5mVkmL6QTqQQmH_4KvuNYVYUyKbPtn9WoUp8 # Replace with your actual ngrok auth token

from pyngrok import ngrok

# Start ngrok tunnel
public_url = ngrok.connect(8501)
print(f"Public URL: {public_url}")

# Run Streamlit app
!streamlit run app.py --server.port 8501